{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking to create a function that plots all the hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import sys,os,os.path\n",
    "sys.path.append(\"../../\") # if you move files around, you need to adjust this!\n",
    "sys.path.append(os.path.expanduser('~/code/eol_hsrl_python'))\n",
    "os.environ['ICTDIR']='/home/e78368jw/Documents/NEXT_CODE/IC'\n",
    "\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "#%matplotlib notebook\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "rcParams['mathtext.fontset'] = 'stix'\n",
    "rcParams['font.family'] = 'STIXGeneral'\n",
    "rcParams['figure.figsize'] = [10, 8]\n",
    "rcParams['font.size'] = 22\n",
    "\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import tables as tb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.colors as clrs\n",
    "\n",
    "import IC.invisible_cities.core.core_functions                   as     coref\n",
    "import IC.invisible_cities.io.dst_io                           as     dstio\n",
    "\n",
    "from IC.invisible_cities.cities                 import beersheba as beerfun\n",
    "\n",
    "from IC.invisible_cities.evm.event_model                          import HitCollection\n",
    "\n",
    "from IC.invisible_cities.database.load_db       import DataSiPM\n",
    "\n",
    "from IC.invisible_cities.evm.event_model        import Cluster, Hit\n",
    "from IC.invisible_cities.types.ic_types         import xy\n",
    "from IC.invisible_cities.reco.paolina_functions import voxelize_hits\n",
    "\n",
    "from IC.invisible_cities.evm.event_model        import HitEnergy\n",
    "from IC.invisible_cities.cities.beersheba          import DeconvolutionMode\n",
    "from IC.invisible_cities.cities.beersheba          import CutType\n",
    "\n",
    "from IC.invisible_cities.reco import hits_functions as hif\n",
    "\n",
    "from IC.invisible_cities.reco.deconv_functions import deconvolve\n",
    "from IC.invisible_cities.reco.deconv_functions import deconvolution_input\n",
    "from IC.invisible_cities.reco.deconv_functions import InterpolationMethod\n",
    "\n",
    "import IC.invisible_cities.io.mcinfo_io as mcio\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def threshold_hits(threshold_charge, same_peak, hitc):\n",
    "    \"\"\"\n",
    "    Applies a threshold to hits and redistributes the charge/energy.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    threshold_charge : float\n",
    "        minimum pes of a hit\n",
    "    same_peak        : bool\n",
    "        whether to reassign NN hits' energy only to the hits from the same peak\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    A function that takes HitCollection as input and returns another object with\n",
    "    only non NN hits of charge above threshold_charge.\n",
    "    The energy of NN hits is redistributed among neighbors.\n",
    "    \"\"\"\n",
    "\n",
    "    t = hitc.time\n",
    "    thr_hits = hif.threshold_hits(hitc.hits, threshold_charge     )\n",
    "    mrg_hits = hif.merge_NN_hits ( thr_hits, same_peak = same_peak)\n",
    "\n",
    "    cor_hits = []\n",
    "    for hit in mrg_hits:\n",
    "        cluster = Cluster(hit.Q, xy(hit.X, hit.Y), hit.var, hit.nsipm)\n",
    "        xypos   = xy(hit.Xpeak, hit.Ypeak)\n",
    "        hit     = Hit(hit.npeak, cluster, hit.Z, hit.E, xypos, hit.Ec)\n",
    "        cor_hits.append(hit)\n",
    "\n",
    "    new_hitc      = HitCollection(hitc.event, t)\n",
    "    new_hitc.hits = cor_hits\n",
    "    return new_hitc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def hits_from_df (dst, skip_NN = False):\n",
    "    \"\"\"\n",
    "    Function that transforms pandas DataFrame dst to HitCollection\n",
    "    ------\n",
    "    Parameters\n",
    "    ------\n",
    "    dst : pd.DataFrame\n",
    "        DataFrame with obligatory columns :\n",
    "                event, npeak, X, Y, Z,  Q, E\n",
    "        If time, nsipm, Xrms, Yrms, Qc, Ec, track_id are not\n",
    "        inside dst the default value is set to -1\n",
    "        If Xpeak, Ypeak not in dst the default value is -1000\n",
    "    ------\n",
    "    Returns\n",
    "    ------\n",
    "    Dictionary {event_number : HitCollection}\n",
    "    from here\n",
    "    https://github.com/next-exp/IC/blob/v2-development/invisible_cities/io/hits_io.py#L16\n",
    "    \"\"\"\n",
    "    all_events = {}\n",
    "    times = getattr(dst, 'time', [-1]*len(dst))\n",
    "    for (event, time) , df in dst.groupby(['event', times]):\n",
    "        #pandas is not consistent with numpy dtypes so we have to change it by hand\n",
    "        event = np.int32(event)\n",
    "        hits  = []\n",
    "        for i, row in df.iterrows():\n",
    "            Q = getattr(row,'Q', row.E)\n",
    "            if skip_NN and Q == NN:\n",
    "                continue\n",
    "            if hasattr(row, 'Xrms'):\n",
    "                Xrms  = row.Xrms\n",
    "                Xrms2 = Xrms**2\n",
    "            else:\n",
    "                Xrms = Xrms2 = -1\n",
    "            if hasattr(row, 'Yrms'):\n",
    "                Yrms  = row.Yrms\n",
    "                Yrms2 = Yrms**2\n",
    "            else:\n",
    "                Yrms = Yrms2 = -1\n",
    "            nsipm   = getattr(row, 'nsipm'   , -1   )     # for backwards compatibility\n",
    "            Qc      = getattr(row, 'Qc'      , -1   )     # for backwards compatibility\n",
    "            Xpeak   = getattr(row, 'Xpeak'   , -1000)     # for backwards compatibility\n",
    "            Ypeak   = getattr(row, 'Ypeak'   , -1000)     # for backwards compatibility\n",
    "            Ec      = getattr(row, 'Ec'      , -1   )     # for backwards compatibility\n",
    "            trackID = getattr(row, 'track_id', -1   )     # for backwards compatibility\n",
    "            Ep      = getattr(row, \"Ep\"      , -1   )     # for backwards compatibility\n",
    "\n",
    "            hit = Hit(row.npeak            ,\n",
    "                      Cluster(Q               ,\n",
    "                              xy(row.X, row.Y),\n",
    "                              xy(Xrms2, Yrms2),\n",
    "                              nsipm = nsipm   ,\n",
    "                              z     = row.Z   ,\n",
    "                              E     = row.E   ,\n",
    "                              Qc    = Qc      ),\n",
    "                      row.Z                ,\n",
    "                      row.E                ,\n",
    "                      xy(Xpeak, Ypeak)     ,\n",
    "                      s2_energy_c = Ec     ,\n",
    "                      track_id    = trackID,\n",
    "                      Ep          = Ep     )\n",
    "\n",
    "            hits.append(hit)\n",
    "\n",
    "        if len(hits):\n",
    "            all_events[event] = HitCollection(event, time, hits=hits)\n",
    "\n",
    "    return all_events\n",
    "\n",
    "def hitc_to_df_(hitc):\n",
    "    columns = defaultdict(list)\n",
    "    for hit in hitc.hits:\n",
    "        columns[\"event\"   ].append(hitc.event)\n",
    "        columns[\"time\"    ].append(hitc.time)\n",
    "        columns[\"npeak\"   ].append(hit .npeak)\n",
    "        columns[\"Xpeak\"   ].append(hit .Xpeak)\n",
    "        columns[\"Ypeak\"   ].append(hit .Ypeak)\n",
    "        columns[\"nsipm\"   ].append(hit .nsipm)\n",
    "        columns[\"X\"       ].append(hit .X)\n",
    "        columns[\"Y\"       ].append(hit .Y)\n",
    "        columns[\"Xrms\"    ].append(hit .Xrms)\n",
    "        columns[\"Yrms\"    ].append(hit .Yrms)\n",
    "        columns[\"Z\"       ].append(hit .Z)\n",
    "        columns[\"Q\"       ].append(hit .Q)\n",
    "        columns[\"E\"       ].append(hit .E)\n",
    "        columns[\"Qc\"      ].append(hit .Qc)\n",
    "        columns[\"Ec\"      ].append(hit .Ec)\n",
    "        columns[\"track_id\"].append(hit .track_id)\n",
    "        columns[\"Ep\"      ].append(hit .Ep)\n",
    "    return pd.DataFrame(columns)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def soph_to_lowTh(df, threshold = 5):\n",
    "    '''\n",
    "    Converts sophronia 'RECO/Events' to lowTh events via a rather convoluted process\n",
    "    Made by me (John Waiton), so dont treat it like a normal function from IC!\n",
    "    ------\n",
    "    Parameters\n",
    "    ------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame with obligatory columns :\n",
    "                event, npeak, X, Y, Z,  Q, E\n",
    "    threshold: int\n",
    "        value at which the threshold is set.\n",
    "    ------\n",
    "    Returns\n",
    "    ------\n",
    "    Dictionary {event_number : HitCollection}\n",
    "    from here\n",
    "    '''\n",
    "\n",
    "    # safety check, to ensure you don't accidentally make a repeating dataframe\n",
    "    \n",
    "\n",
    "\n",
    "    # new parameters for threshold, this is silly but I'm copying previous convention\n",
    "    pes = 1\n",
    "    threshold = threshold * pes\n",
    "    same_peak = True\n",
    "\n",
    "    # convert sophronia RECO/Events to hit collection\n",
    "    soph_hitc = hits_from_df(df)\n",
    "\n",
    "    # collect the keys as the event numbers\n",
    "    soph_hitc_list = list(soph_hitc.keys())\n",
    "\n",
    "    print(\"Processing data...\")\n",
    "    # loop over all of these events\n",
    "    j = 0\n",
    "    for i in soph_hitc_list:\n",
    "        j += 1\n",
    "\n",
    "        if (len(soph_hitc_list)%j == 50): \n",
    "            print(\"{}/{}\".format(j, len(soph_hitc_list)))\n",
    "        # choose i'th event\n",
    "        soph_hit_event = soph_hitc.get(i)\n",
    "\n",
    "        # Apply threshold calculation\n",
    "        soph_hitc_lowTh = threshold_hits(threshold, same_peak, soph_hit_event)\n",
    "\n",
    "        # convert back to pandas dataframe using hitc_to_df\n",
    "        soph_hdst_lowTh = hitc_to_df_(soph_hitc_lowTh)\n",
    "\n",
    "        # check if pandas dataframe with all the events exists yet\n",
    "        if 'full_soph_df' in locals() and isinstance(full_soph_df, pd.DataFrame):\n",
    "            full_soph_df = pd.concat([full_soph_df, soph_hdst_lowTh])\n",
    "        else:\n",
    "            full_soph_df = soph_hdst_lowTh.copy(deep = True)\n",
    "    \n",
    "    return full_soph_df\n",
    "\n",
    "def return_id(number):\n",
    "    return str(df_ps[df_ps.particle_id == number].particle_name.values).strip(\"'[]'\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### choose a file of your liking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "datatype = 'MC'\n",
    "\n",
    "evt_list = np.load('port_1a_isaura_lost_evts.npy')/2\n",
    "\n",
    "# loading sophronia file\n",
    "#soph_file = f'../../../next_misc/Tl_studies/sophronia/sophronia_qthr2.h5'\n",
    "folder_path = f'/home/e78368jw/Documents/NEXT_CODE/next_misc/FOM_merge&fit/12_12_18/PORT_1a/isaura/'\n",
    "\n",
    "file_names = [f for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f)) and f.endswith('.h5')]\n",
    "\n",
    "\n",
    "for file in tqdm(file_names):\n",
    "    soph_file = folder_path + file\n",
    "\n",
    "\n",
    "\n",
    "    if (datatype == 'MC'):\n",
    "        evtmap = mcio.load_eventnumbermap(soph_file).set_index('nexus_evt')\n",
    "        true_info = mcio.load_mchits_df(soph_file).reset_index()\n",
    "        #true_info.event_id = true_info.event_id.map(evtmap.evt_number)\n",
    "        \n",
    "        # select only events that show up in the relevant\n",
    "        events = np.unique(true_info.event_id.values)\n",
    "        useful_events = [x for x in events if x in evt_list]\n",
    "        #print(\"Events in file {}: {}\".format(file, useful_events))\n",
    "\n",
    "        for i in range(len(useful_events)):\n",
    "            \n",
    "            this_evt_true_info = true_info[true_info.event_id == useful_events[i]]\n",
    "\n",
    "            #soph_hdst = dstio.load_dst(soph_file, 'DECO', 'Events')#CHITS/lowTh\n",
    "            #thresh = 4\n",
    "           \n",
    "            \n",
    "            #hits = soph_to_lowTh(soph_hdst, threshold = thresh)\n",
    "            #display(hits)\n",
    "            #hits = hits[hits.event == useful_events[i]*2]\n",
    "\n",
    "            #x_range = (hits.X.max()-hits.X.min())/2.\n",
    "            #y_range = (hits.Y.max()-hits.Y.min())/2.\n",
    "            #z_range = (hits.Z.max()-hits.Z.min())/2.\n",
    "            #mid_x   = (hits.X.max()+hits.X.min())/2.\n",
    "            #mid_y   = (hits.Y.max()+hits.Y.min())/2.\n",
    "            #mid_z   = (hits.Z.max()+hits.Z.min())/2.\n",
    "\n",
    "            #print(\"X maximum and minimum\")\n",
    "            #print(hits.X.max(), hits.X.min())\n",
    "            #print(\"\")\n",
    "\n",
    "            #print(\"Y maximum and minimum\")\n",
    "            #print(hits.Y.max(), hits.Y.min())\n",
    "            #print(\"\")\n",
    "\n",
    "            #print(\"Z maximum and minimum\")\n",
    "            #print(hits.Z.max(), hits.Z.min())\n",
    "\n",
    "            #xbins = int(hits.X.max()-hits.X.min())\n",
    "            #ybins = int(hits.Y.max()-hits.Y.min())\n",
    "            #zbins = int((hits.Z.max()-hits.Z.min())/2.)\n",
    "\n",
    "\n",
    "            df_ps = pd.read_hdf(soph_file, 'MC/particles')\n",
    "            df_ps = df_ps[df_ps.event_id == useful_events[i]]\n",
    "\n",
    "            this_evt_true_info['particle_name'] = this_evt_true_info['particle_id'].apply(return_id)\n",
    "\n",
    "            xt = this_evt_true_info.x\n",
    "            yt = this_evt_true_info.y\n",
    "            zt = this_evt_true_info.z\n",
    "            et = this_evt_true_info.energy*1000\n",
    "\n",
    "            for pid, df in this_evt_true_info.groupby('particle_name'):\n",
    "\n",
    "                xt = df.x\n",
    "                yt = df.y\n",
    "                zt = df.z\n",
    "                et = df.energy*1000\n",
    "\n",
    "                if (pid == 'gamma') or (pid == 'Xe131'):\n",
    "                    plt.scatter(xt, yt,  alpha=1, label = str(pid))\n",
    "                else:\n",
    "                    plt.scatter(xt, yt,  alpha=0.1, label = str(pid))\n",
    "\n",
    "                \n",
    "            plt.xlabel('X (mm)');\n",
    "            plt.ylabel('Y (mm)');\n",
    "\n",
    "            # Retrieve legend handles and labels\n",
    "            handles, labels = plt.gca().get_legend_handles_labels()\n",
    "\n",
    "            # Create a single legend for all subplots\n",
    "            legend = plt.legend(handles, labels, fontsize=15)\n",
    "            for handle in legend.legendHandles:\n",
    "                handle.set_alpha(1.0)\n",
    "\n",
    "            plt.title('True Hits_' + str(useful_events[i]), fontsize=30)\n",
    "            plt.savefig('hits_plots/' + str(useful_events[i]) + '.png')\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "            # then applying transformations to convert to 'SiPM outputs'\n",
    "            fig, axes = plt.subplots(1, 3, figsize=(18, 4))\n",
    "\n",
    "\n",
    "            #xx = np.arange(hits.X.min(), hits.X.max() + pitch, pitch)\n",
    "            #yy = np.arange(hits.Y.min(), hits.Y.max() + pitch, pitch)\n",
    "            #zz = hits.Z.unique()\n",
    "\n",
    "            #axes[0].hist2d(hits.X, hits.Y, bins=[xx, yy], weights=hits.Q, cmin=0.0001);\n",
    "            #axes[0].set_xlabel('X (mm)');\n",
    "            #axes[0].set_ylabel('Y (mm)');\n",
    "\n",
    "            #axes[1].hist2d(hits.X, hits.Z, bins=[xx, zz], weights=hits.Q, cmin=0.0001);\n",
    "            #axes[1].set_xlim([-75, 25])\n",
    "            #axes[1].set_xlabel('X (mm)');\n",
    "            #axes[1].set_ylabel('Z (mm)');\n",
    "\n",
    "\n",
    "            #axes[2].hist2d(hits.Y, hits.Z, bins=[yy, zz], weights=hits.Q, cmin=0.0001);\n",
    "            #axes[2].set_xlabel('Y (mm)');\n",
    "            #axes[2].set_ylabel('Z (mm)');\n",
    "\n",
    "            #fig.suptitle('Sensors Signal_' +  str(useful_events[i]), fontsize=30)\n",
    "            #fig.savefig('hits_plots/' + str(useful_events[i]) + '_sensor.png')\n",
    "            #plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IC-3.8-2022-04-13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
