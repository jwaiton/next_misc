{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### quick plotter for looking at the way RL deconv works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import sys,os,os.path\n",
    "sys.path.append(\"../../\") # if you move files around, you need to adjust this!\n",
    "sys.path.append(os.path.expanduser('~/code/eol_hsrl_python'))\n",
    "os.environ['ICTDIR']='/home/e78368jw/Documents/NEXT_CODE/IC'\n",
    "\n",
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "#%matplotlib notebook\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "rcParams['mathtext.fontset'] = 'stix'\n",
    "rcParams['font.family'] = 'STIXGeneral'\n",
    "rcParams['figure.figsize'] = [10, 8]\n",
    "rcParams['font.size'] = 22\n",
    "\n",
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import tables as tb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.colors as clrs\n",
    "\n",
    "import IC.invisible_cities.core.core_functions                   as     coref\n",
    "import IC.invisible_cities.io.dst_io                           as     dstio\n",
    "\n",
    "from IC.invisible_cities.cities                 import beersheba as beerfun\n",
    "\n",
    "from IC.invisible_cities.evm.event_model                          import HitCollection\n",
    "\n",
    "from IC.invisible_cities.database.load_db       import DataSiPM\n",
    "\n",
    "from IC.invisible_cities.evm.event_model        import Cluster, Hit\n",
    "from IC.invisible_cities.types.ic_types         import xy\n",
    "from IC.invisible_cities.reco.paolina_functions import voxelize_hits\n",
    "\n",
    "from IC.invisible_cities.evm.event_model        import HitEnergy\n",
    "from IC.invisible_cities.cities.beersheba          import DeconvolutionMode\n",
    "from IC.invisible_cities.cities.beersheba          import CutType\n",
    "\n",
    "from IC.invisible_cities.reco import hits_functions as hif\n",
    "\n",
    "from IC.invisible_cities.reco.deconv_functions import deconvolve\n",
    "from IC.invisible_cities.reco.deconv_functions import deconvolution_input\n",
    "from IC.invisible_cities.reco.deconv_functions import InterpolationMethod\n",
    "\n",
    "import IC.invisible_cities.io.mcinfo_io as mcio\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import Normalize\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def threshold_hits(threshold_charge, same_peak, hitc):\n",
    "    \"\"\"\n",
    "    Applies a threshold to hits and redistributes the charge/energy.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    threshold_charge : float\n",
    "        minimum pes of a hit\n",
    "    same_peak        : bool\n",
    "        whether to reassign NN hits' energy only to the hits from the same peak\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    A function that takes HitCollection as input and returns another object with\n",
    "    only non NN hits of charge above threshold_charge.\n",
    "    The energy of NN hits is redistributed among neighbors.\n",
    "    \"\"\"\n",
    "\n",
    "    t = hitc.time\n",
    "    thr_hits = hif.threshold_hits(hitc.hits, threshold_charge     )\n",
    "    mrg_hits = hif.merge_NN_hits ( thr_hits, same_peak = same_peak)\n",
    "\n",
    "    cor_hits = []\n",
    "    for hit in mrg_hits:\n",
    "        cluster = Cluster(hit.Q, xy(hit.X, hit.Y), hit.var, hit.nsipm)\n",
    "        xypos   = xy(hit.Xpeak, hit.Ypeak)\n",
    "        hit     = Hit(hit.npeak, cluster, hit.Z, hit.E, xypos, hit.Ec)\n",
    "        cor_hits.append(hit)\n",
    "\n",
    "    new_hitc      = HitCollection(hitc.event, t)\n",
    "    new_hitc.hits = cor_hits\n",
    "    return new_hitc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def hits_from_df (dst, skip_NN = False):\n",
    "    \"\"\"\n",
    "    Function that transforms pandas DataFrame dst to HitCollection\n",
    "    ------\n",
    "    Parameters\n",
    "    ------\n",
    "    dst : pd.DataFrame\n",
    "        DataFrame with obligatory columns :\n",
    "                event, npeak, X, Y, Z,  Q, E\n",
    "        If time, nsipm, Xrms, Yrms, Qc, Ec, track_id are not\n",
    "        inside dst the default value is set to -1\n",
    "        If Xpeak, Ypeak not in dst the default value is -1000\n",
    "    ------\n",
    "    Returns\n",
    "    ------\n",
    "    Dictionary {event_number : HitCollection}\n",
    "    from here\n",
    "    https://github.com/next-exp/IC/blob/v2-development/invisible_cities/io/hits_io.py#L16\n",
    "    \"\"\"\n",
    "    all_events = {}\n",
    "    times = getattr(dst, 'time', [-1]*len(dst))\n",
    "    for (event, time) , df in dst.groupby(['event', times]):\n",
    "        #pandas is not consistent with numpy dtypes so we have to change it by hand\n",
    "        event = np.int32(event)\n",
    "        hits  = []\n",
    "        for i, row in df.iterrows():\n",
    "            Q = getattr(row,'Q', row.E)\n",
    "            if skip_NN and Q == NN:\n",
    "                continue\n",
    "            if hasattr(row, 'Xrms'):\n",
    "                Xrms  = row.Xrms\n",
    "                Xrms2 = Xrms**2\n",
    "            else:\n",
    "                Xrms = Xrms2 = -1\n",
    "            if hasattr(row, 'Yrms'):\n",
    "                Yrms  = row.Yrms\n",
    "                Yrms2 = Yrms**2\n",
    "            else:\n",
    "                Yrms = Yrms2 = -1\n",
    "            nsipm   = getattr(row, 'nsipm'   , -1   )     # for backwards compatibility\n",
    "            Qc      = getattr(row, 'Qc'      , -1   )     # for backwards compatibility\n",
    "            Xpeak   = getattr(row, 'Xpeak'   , -1000)     # for backwards compatibility\n",
    "            Ypeak   = getattr(row, 'Ypeak'   , -1000)     # for backwards compatibility\n",
    "            Ec      = getattr(row, 'Ec'      , -1   )     # for backwards compatibility\n",
    "            trackID = getattr(row, 'track_id', -1   )     # for backwards compatibility\n",
    "            Ep      = getattr(row, \"Ep\"      , -1   )     # for backwards compatibility\n",
    "\n",
    "            hit = Hit(row.npeak            ,\n",
    "                      Cluster(Q               ,\n",
    "                              xy(row.X, row.Y),\n",
    "                              xy(Xrms2, Yrms2),\n",
    "                              nsipm = nsipm   ,\n",
    "                              z     = row.Z   ,\n",
    "                              E     = row.E   ,\n",
    "                              Qc    = Qc      ),\n",
    "                      row.Z                ,\n",
    "                      row.E                ,\n",
    "                      xy(Xpeak, Ypeak)     ,\n",
    "                      s2_energy_c = Ec     ,\n",
    "                      track_id    = trackID,\n",
    "                      Ep          = Ep     )\n",
    "\n",
    "            hits.append(hit)\n",
    "\n",
    "        if len(hits):\n",
    "            all_events[event] = HitCollection(event, time, hits=hits)\n",
    "\n",
    "    return all_events\n",
    "\n",
    "def hitc_to_df_(hitc):\n",
    "    columns = defaultdict(list)\n",
    "    for hit in hitc.hits:\n",
    "        columns[\"event\"   ].append(hitc.event)\n",
    "        columns[\"time\"    ].append(hitc.time)\n",
    "        columns[\"npeak\"   ].append(hit .npeak)\n",
    "        columns[\"Xpeak\"   ].append(hit .Xpeak)\n",
    "        columns[\"Ypeak\"   ].append(hit .Ypeak)\n",
    "        columns[\"nsipm\"   ].append(hit .nsipm)\n",
    "        columns[\"X\"       ].append(hit .X)\n",
    "        columns[\"Y\"       ].append(hit .Y)\n",
    "        columns[\"Xrms\"    ].append(hit .Xrms)\n",
    "        columns[\"Yrms\"    ].append(hit .Yrms)\n",
    "        columns[\"Z\"       ].append(hit .Z)\n",
    "        columns[\"Q\"       ].append(hit .Q)\n",
    "        columns[\"E\"       ].append(hit .E)\n",
    "        columns[\"Qc\"      ].append(hit .Qc)\n",
    "        columns[\"Ec\"      ].append(hit .Ec)\n",
    "        columns[\"track_id\"].append(hit .track_id)\n",
    "        columns[\"Ep\"      ].append(hit .Ep)\n",
    "    return pd.DataFrame(columns)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def soph_to_lowTh(df, threshold = 5):\n",
    "    '''\n",
    "    Converts sophronia 'RECO/Events' to lowTh events via a rather convoluted process\n",
    "    Made by me (John Waiton), so dont treat it like a normal function from IC!\n",
    "    ------\n",
    "    Parameters\n",
    "    ------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame with obligatory columns :\n",
    "                event, npeak, X, Y, Z,  Q, E\n",
    "    threshold: int\n",
    "        value at which the threshold is set.\n",
    "    ------\n",
    "    Returns\n",
    "    ------\n",
    "    Dictionary {event_number : HitCollection}\n",
    "    from here\n",
    "    '''\n",
    "\n",
    "    # safety check, to ensure you don't accidentally make a repeating dataframe\n",
    "    \n",
    "\n",
    "\n",
    "    # new parameters for threshold, this is silly but I'm copying previous convention\n",
    "    pes = 1\n",
    "    threshold = threshold * pes\n",
    "    same_peak = True\n",
    "\n",
    "    # convert sophronia RECO/Events to hit collection\n",
    "    soph_hitc = hits_from_df(df)\n",
    "\n",
    "    # collect the keys as the event numbers\n",
    "    soph_hitc_list = list(soph_hitc.keys())\n",
    "\n",
    "    print(\"Processing data...\")\n",
    "    # loop over all of these events\n",
    "    j = 0\n",
    "    for i in soph_hitc_list:\n",
    "        j += 1\n",
    "\n",
    "        if (len(soph_hitc_list)%j == 50): \n",
    "            print(\"{}/{}\".format(j, len(soph_hitc_list)))\n",
    "        # choose i'th event\n",
    "        soph_hit_event = soph_hitc.get(i)\n",
    "\n",
    "        # Apply threshold calculation\n",
    "        soph_hitc_lowTh = threshold_hits(threshold, same_peak, soph_hit_event)\n",
    "\n",
    "        # convert back to pandas dataframe using hitc_to_df\n",
    "        soph_hdst_lowTh = hitc_to_df_(soph_hitc_lowTh)\n",
    "\n",
    "        # check if pandas dataframe with all the events exists yet\n",
    "        if 'full_soph_df' in locals() and isinstance(full_soph_df, pd.DataFrame):\n",
    "            full_soph_df = pd.concat([full_soph_df, soph_hdst_lowTh])\n",
    "        else:\n",
    "            full_soph_df = soph_hdst_lowTh.copy(deep = True)\n",
    "    \n",
    "    return full_soph_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data...\n",
      "133/316\n",
      "266/316\n"
     ]
    }
   ],
   "source": [
    "# loading sophronia file\n",
    "soph_file = f'/home/e78368jw/Documents/NEXT_CODE/next_misc/miscellaneous/testing_data/sophronia_27_208Tl.h5'\n",
    "soph_hdst = dstio.load_dst(soph_file, 'RECO', 'Events')#CHITS/lowTh\n",
    "\n",
    "# set q_thr value here\n",
    "thresh = 4\n",
    "soph_lowTh = soph_to_lowTh(soph_hdst, threshold = thresh)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Beersheba crap\n",
    "# Input file and some event IDs to look at.\n",
    "dist = 12\n",
    "typefile = 'esmeralda' #'esmeralda'\n",
    "evts = [90] #15, 30, 90\n",
    "pitch = 15.55\n",
    "detector_db     = 'localdb.NEXT100DB.sqlite3'\n",
    "run_number      = -1\n",
    "\n",
    "datatype = 'MC'\n",
    "\n",
    "\n",
    "# Parameters involved in beersheba city and the deconvolution.\n",
    "pes = 1\n",
    "threshold = thresh * pes\n",
    "same_peak = True\n",
    "\n",
    "deconv_params = dict(\n",
    "                  drop_dist       = [16., 16.],\n",
    "                  psf_fname       = f'/home/e78368jw/Documents/NEXT_CODE/next_misc/Tl_studies/LPR/LightTables/NEXT100_PSF_kr83m_5bar.h5',\n",
    "                  q_cut           = thresh,                   # WE HAVE MANUALLY CHANGED THIS FROM 10 -> 5 HERE\n",
    "                  e_cut           = 9e-3,                # WE HAVE MANUALLY CHANGED THIS FROM 12e-3 TO 6e-3\n",
    "                  n_iterations    = 75,\n",
    "                  iteration_tol   = 1e-10,\n",
    "                  sample_width    = [15.55, 15.55],\n",
    "                  bin_size        = [ 1.,  1.],\n",
    "                  energy_type     = HitEnergy.Ec,               #Removing these variables because they were previously? \n",
    "                  diffusion       = (1., 0.2),\n",
    "                  deconv_mode     = DeconvolutionMode.joint,\n",
    "                  n_dim           = 2,\n",
    "                  cut_type        = CutType.abs,              #Removing these variables because they were previously?\n",
    "                  inter_method    = InterpolationMethod.cubic)            #Removing these variables because they were previously?  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#DeconvolutionMode\n",
    "                \n",
    "deconv_params_   = {k : v for k, v in deconv_params.items() if k not in ['q_cut', 'drop_dist']}\n",
    "\n",
    "# Couple of functions used in beersheba.\n",
    "cut_sensors       = beerfun.cut_over_Q   (deconv_params['q_cut'    ], ['E', 'Ec'])\n",
    "drop_sensors      = beerfun.drop_isolated(deconv_params['drop_dist'], ['E', 'Ec'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "520470\n",
      "X maximum and minimum\n",
      "412.075 -474.275\n",
      "\n",
      "Y maximum and minimum\n",
      "147.725 -287.675\n",
      "\n",
      "Z maximum and minimum\n",
      "977.7684000000002 877.7499937500002\n",
      "Cutting sensors below 4\n",
      "Time spent in cut_over_Q: 0.03562211990356445 s\n",
      "Time spent in drop_isolated: 0.037636756896972656 s\n"
     ]
    }
   ],
   "source": [
    "hdst = soph_lowTh\n",
    "\n",
    "\n",
    "# select event\n",
    "evt  = hdst.event.unique()[230]\n",
    "print(evt)\n",
    "hits = hdst[hdst.event == evt]\n",
    "\n",
    "\n",
    "# take positions pre-cuts\n",
    "x_range = (hits.X.max()-hits.X.min())/2.\n",
    "y_range = (hits.Y.max()-hits.Y.min())/2.\n",
    "z_range = (hits.Z.max()-hits.Z.min())/2.\n",
    "mid_x   = (hits.X.max()+hits.X.min())/2.\n",
    "mid_y   = (hits.Y.max()+hits.Y.min())/2.\n",
    "mid_z   = (hits.Z.max()+hits.Z.min())/2.\n",
    "\n",
    "print(\"X maximum and minimum\")\n",
    "print(hits.X.max(), hits.X.min())\n",
    "print(\"\")\n",
    "\n",
    "print(\"Y maximum and minimum\")\n",
    "print(hits.Y.max(), hits.Y.min())\n",
    "print(\"\")\n",
    "\n",
    "print(\"Z maximum and minimum\")\n",
    "print(hits.Z.max(), hits.Z.min())\n",
    "\n",
    "xbins = int(hits.X.max()-hits.X.min())\n",
    "ybins = int(hits.Y.max()-hits.Y.min())\n",
    "zbins = int((hits.Z.max()-hits.Z.min())/2.)\n",
    "\n",
    "\n",
    "if (datatype == 'MC'):\n",
    "    evtmap = mcio.load_eventnumbermap(soph_file).set_index('nexus_evt')\n",
    "    true_info = mcio.load_mchits_df(soph_file).reset_index()\n",
    "    true_info.event_id = true_info.event_id.map(evtmap.evt_number)\n",
    "    \n",
    "    \n",
    "    this_evt_true_info = true_info[true_info.event_id == evt]\n",
    "\n",
    "    xt = this_evt_true_info.x\n",
    "    yt = this_evt_true_info.y\n",
    "    zt = this_evt_true_info.z\n",
    "    et = this_evt_true_info.energy*1000\n",
    "\n",
    "\n",
    "# cut, drop, etc\n",
    "qmin = deconv_params['q_cut']\n",
    "print(f'Cutting sensors below {qmin}')\n",
    "hits_cut = coref.timefunc(cut_sensors)(hits.copy())\n",
    "hits_drop = coref.timefunc(drop_sensors)(hits_cut.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deconvolve here\n",
    "where the magic happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "``/home/e78368jw/Documents/NEXT_CODE/next_misc/beersheba_work/f/home/e78368jw/Documents/NEXT_CODE/next_misc/Tl_studies/LPR/LightTables/NEXT100_PSF_kr83m_5bar.h5`` does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m deconvolver \u001b[38;5;241m=\u001b[39m \u001b[43mbeerfun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeconvolve_signal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDataSiPM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdetector_db\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_number\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdeconv_params_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m hits_deco \u001b[38;5;241m=\u001b[39m coref\u001b[38;5;241m.\u001b[39mtimefunc(deconvolver)(hits_drop\u001b[38;5;241m.\u001b[39mcopy())\n",
      "File \u001b[0;32m~/Documents/NEXT_CODE/next_misc/beersheba_work/../../IC/invisible_cities/core/configure.py:249\u001b[0m, in \u001b[0;36mcheck_annotations.<locals>.checked_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    247\u001b[0m     first_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    248\u001b[0m     compare_signature_to_values(f, args, kwargs)\n\u001b[0;32m--> 249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/NEXT_CODE/next_misc/beersheba_work/../../IC/invisible_cities/cities/beersheba.py:143\u001b[0m, in \u001b[0;36mdeconvolve_signal\u001b[0;34m(det_db, psf_fname, e_cut, n_iterations, iteration_tol, sample_width, bin_size, diffusion, energy_type, deconv_mode, n_dim, cut_type, inter_method, n_iterations_g)\u001b[0m\n\u001b[1;32m    140\u001b[0m bin_size      \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(bin_size               )\n\u001b[1;32m    141\u001b[0m diffusion     \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(diffusion              )\n\u001b[0;32m--> 143\u001b[0m psfs          \u001b[38;5;241m=\u001b[39m \u001b[43mload_dst\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpsf_fname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPSF\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPSFs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m det_grid      \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39marange(det_db[var]\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m+\u001b[39m bs\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m, det_db[var]\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m-\u001b[39m bs\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mfinfo(np\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39meps, bs)\n\u001b[1;32m    145\u001b[0m                  \u001b[38;5;28;01mfor\u001b[39;00m var, bs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(dimensions, bin_size)]\n\u001b[1;32m    146\u001b[0m deconvolution \u001b[38;5;241m=\u001b[39m deconvolve(n_iterations, iteration_tol,\n\u001b[1;32m    147\u001b[0m                            sample_width, det_grid       , inter_method)\n",
      "File \u001b[0;32m~/Documents/NEXT_CODE/next_misc/beersheba_work/../../IC/invisible_cities/io/dst_io.py:46\u001b[0m, in \u001b[0;36mload_dst\u001b[0;34m(filename, group, node, evt_list, ignore_errors)\u001b[0m\n\u001b[1;32m     44\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m does not exist: file = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;167;01mUserWarning\u001b[39;00m)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mread_dst_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevt_list\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/NEXT_CODE/next_misc/beersheba_work/../../IC/invisible_cities/io/dst_io.py:27\u001b[0m, in \u001b[0;36mload_dst.<locals>.read_dst_\u001b[0;34m(filename, group, node, evt_list)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_dst_\u001b[39m(filename, group, node, evt_list):\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mtb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m h5in:\n\u001b[1;32m     28\u001b[0m         table  \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(h5in\u001b[38;5;241m.\u001b[39mroot, group), node)\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m evt_list \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/IC-3.8-2022-04-13/lib/python3.8/site-packages/tables/file.py:300\u001b[0m, in \u001b[0;36mopen_file\u001b[0;34m(filename, mode, title, root_uep, filters, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    296\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe file \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is already opened.  Please \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    297\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclose it before reopening in write mode.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m filename)\n\u001b[1;32m    299\u001b[0m \u001b[38;5;66;03m# Finally, create the File instance, and return it\u001b[39;00m\n\u001b[0;32m--> 300\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroot_uep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/IC-3.8-2022-04-13/lib/python3.8/site-packages/tables/file.py:750\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, filename, mode, title, root_uep, filters, **kwargs)\u001b[0m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams \u001b[38;5;241m=\u001b[39m params\n\u001b[1;32m    749\u001b[0m \u001b[38;5;66;03m# Now, it is time to initialize the File extension\u001b[39;00m\n\u001b[0;32m--> 750\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_g_new\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;66;03m# Check filters and set PyTables format version for new files.\u001b[39;00m\n\u001b[1;32m    753\u001b[0m new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_v_new\n",
      "File \u001b[0;32m~/anaconda3/envs/IC-3.8-2022-04-13/lib/python3.8/site-packages/tables/hdf5extension.pyx:368\u001b[0m, in \u001b[0;36mtables.hdf5extension.File._g_new\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/IC-3.8-2022-04-13/lib/python3.8/site-packages/tables/utils.py:143\u001b[0m, in \u001b[0;36mcheck_file_access\u001b[0;34m(filename, mode)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;66;03m# The file should be readable.\u001b[39;00m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39maccess(path, os\u001b[38;5;241m.\u001b[39mF_OK):\n\u001b[0;32m--> 143\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m``\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`` does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mis_file():\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m``\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`` is not a regular file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: ``/home/e78368jw/Documents/NEXT_CODE/next_misc/beersheba_work/f/home/e78368jw/Documents/NEXT_CODE/next_misc/Tl_studies/LPR/LightTables/NEXT100_PSF_kr83m_5bar.h5`` does not exist"
     ]
    }
   ],
   "source": [
    "deconvolver = beerfun.deconvolve_signal(DataSiPM(detector_db, run_number), **deconv_params_)\n",
    "hits_deco = coref.timefunc(deconvolver)(hits_drop.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IC-3.8-2022-04-13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
