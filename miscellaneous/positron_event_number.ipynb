{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checking the number of positron events totalling in each port via the MC\n",
    "\n",
    "idk why i didnt check this earlier, should have been obvious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# import stuff\n",
    "import sys,os,os.path\n",
    "\n",
    "sys.path.append(\"../../\")   # cite IC from parent directory\n",
    "sys.path.append(\"/home/e78368jw/Documents/NEXT_CODE/next_misc/\")\n",
    "#sys.path.append(os.path.expanduser('~/code/eol_hsrl_python'))\n",
    "os.environ['ICTDIR']='/home/e78368jw/Documents/NEXT_CODE/IC'\n",
    "import IC.invisible_cities.io.dst_io                           as     dstio\n",
    "import IC.invisible_cities.io.mcinfo_io as mcio\n",
    "from    IC.invisible_cities.core.core_functions   import shift_to_bin_centers\n",
    "\n",
    "import core.functions as func\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import scipy.special as special\n",
    "from scipy.stats import skewnorm\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "from scipy.integrate import quad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def collate_ports(path_array):\n",
    "    '''\n",
    "    Collect individual ports and merge the information\n",
    "\n",
    "    Args:\n",
    "        path_array          :           an array of folder paths to h5 files\n",
    "                                        respective of the multiple ports\n",
    "\n",
    "    \n",
    "    Returns:\n",
    "        array               :           output of collective ports\n",
    "    '''\n",
    "\n",
    "    # strip array except from port information\n",
    "    port_id = [x.split('PORT_')[1][:2] for x in path_array]\n",
    "\n",
    "    for i in range(len(path_array)):\n",
    "        print(\"Porting {}\".format(path_array[i]))\n",
    "        if (i==0):\n",
    "            x = (func.load_data(path_array[i]))\n",
    "            tracks = x[0]\n",
    "            #particles = x[1]\n",
    "            # match tracks for particle\n",
    "            #particles['event_id'] = particles['event_id'] * ((i+1)*2)\n",
    "            # add on the column for port ID\n",
    "            tracks['PORT'] = str(port_id[i])\n",
    "        else:\n",
    "            nu_x = (func.load_data(path_array[i]))\n",
    "            nu_tracks = nu_x[0]\n",
    "            #nu_particles = nu_x[1]\n",
    "            print(\"Tracks: {}\".format(func.len_events(nu_tracks)))\n",
    "            # multiply the events numbers to avoid overlap\n",
    "            nu_tracks['event'] = nu_tracks['event'] * (i+1)\n",
    "            nu_tracks['PORT'] = str(port_id[i])\n",
    "            #nu_particles['event_id'] = nu_particles['event_id'] * ((i+1)*2)\n",
    "\n",
    "\n",
    "            tracks = tracks.append(nu_tracks)\n",
    "            #particles = particles.append(nu_particles)\n",
    "\n",
    "        print(\"Done! Tracks available: {}\".format(func.len_events(tracks)))\n",
    "    \n",
    "    return tracks\n",
    "\n",
    "def positron_ports(path_array):\n",
    "    '''\n",
    "    Collect positron events from multiple ports.\n",
    "    Bespoke, use with care.\n",
    "    '''\n",
    "\n",
    "    for i in range(len(path_array)):\n",
    "        print(\"Loading positrons from {}\".format(path_array[i]))\n",
    "        if (i==0):\n",
    "            posi = func.positron_scraper(path_array[i])\n",
    "            # multiply the event numbers to match track values\n",
    "            posi['event_id'] = posi['event_id'] * ((i+1)*2)\n",
    "        else:\n",
    "            nu_posi = func.positron_scraper(path_array[i])\n",
    "            print(\"Positron events: {}\".format(func.len_events(nu_posi, tag = 'event_id')))\n",
    "            # multiple the event numbers to avoid overlap, the *2 is to match it with the tracking values\n",
    "            nu_posi['event_id'] = nu_posi['event_id'] * ((i+1)*2)\n",
    "            posi = posi.append(nu_posi)\n",
    "        print(\"Port finished! Tracks available: {}\".format(func.len_events(posi, tag = 'event_id')))\n",
    "    \n",
    "    return posi\n",
    "\n",
    "\n",
    "# a modified version of the positron scraper\n",
    "def MC_collector(data_path, event_list, save = False):\n",
    "    '''\n",
    "    a modified version of the positron scraper\n",
    "    that only collects events found within the event list\n",
    "    this only works for port 1a at the moment, because I\n",
    "    would need to add an event/port mapping function and im too lazy\n",
    "    '''\n",
    "\n",
    "\n",
    "\n",
    "     # collect all filenames\n",
    "    try:\n",
    "        file_names = [f for f in os.listdir(data_path) if os.path.isfile(os.path.join(data_path, f)) and f.endswith('.h5')]\n",
    "    except:\n",
    "        print(\"File path incorrect, please state the correct file path\\n(but not any particular folder!)\")\n",
    "\n",
    "\n",
    "    # read in a singular file to collect the column titles\n",
    "    \n",
    "    MC_df_single = pd.read_hdf(data_path + file_names[0], 'MC/particles')\n",
    "\n",
    "    MC_df = []\n",
    "    pos_df = pd.DataFrame(columns = MC_df_single.columns)\n",
    "    eventmap = []\n",
    "\n",
    "\n",
    "    i = 0\n",
    "    \n",
    "\n",
    "    # how much you chunk your data\n",
    "    chunker = np.floor(len(file_names)*0.1)\n",
    "\n",
    "    # chunk file_names\n",
    "    \n",
    "    for file in file_names:\n",
    "        file_path = data_path + file\n",
    "\n",
    "        # load in file\n",
    "        MC_df_temp = pd.read_hdf(file_path, 'MC/particles')\n",
    "        MC_df.append(MC_df_temp)\n",
    "        eventmap.append(mcio.load_eventnumbermap(file_path).set_index('nexus_evt'))\n",
    "\n",
    "\n",
    "        i += 1\n",
    "\n",
    "        # chunk checker, every time you hit a certain chunk,\n",
    "        # collect the positron events and wipe the df\n",
    "        if ((i%chunker) == 0):\n",
    "            #print(\"Chunking at event {}!\".format(i))\n",
    "            # concat the list\n",
    "            MC_df = pd.concat(MC_df, axis = 0, ignore_index = True)\n",
    "            #print(\"Post concat\")\n",
    "            #display(MC_df)\n",
    "            # alter all the event list numbers by multiples of 2\n",
    "            MC_df['event_id'] = MC_df['event_id'] * 2\n",
    "            pos_data = MC_df[MC_df['event_id'].isin(event_list)]\n",
    "\n",
    "            \n",
    "            #display(pos_data)\n",
    "            #print(type(pos_data))\n",
    "            # collect positron events into df\n",
    "            pos_df = pos_df.append(pos_data)\n",
    "            #print(\"{} positron events found\\n{} positron events total\".format(pos_data.shape[0],pos_df.shape[0]))\n",
    "            #display(pos_df)\n",
    "\n",
    "            # make space\n",
    "            MC_df = []\n",
    "\n",
    "    if (save == True):\n",
    "        pos_df.to_hdf('positrons.h5', key = 'pos', mode = 'w')\n",
    "\n",
    "    return pos_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "folder_paths = ['../FOM_merge&fit/75_9e-3/PORT_1a/isaura/', '../FOM_merge&fit/75_9e-3/PORT_1b/isaura/',  '../FOM_merge&fit/75_9e-3/PORT_2a/isaura/',  '../FOM_merge&fit/75_9e-3/PORT_2b/isaura/']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS DOESNT WORK HOW YOU WANT, BUT ITS CLOSE!\n",
    "# YOU NEED SOMETHING THAT COLLECTS ONLY POSITRON EVENTS THAT OUTPUT\n",
    "# GAMMAS THAT ESCAPE I THINK\n",
    "for i in range(len(folder_paths)):\n",
    "    particles = MC_collector(folder_paths[i], merge_events_np)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IC-3.8-2022-04-13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
